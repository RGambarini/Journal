<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://rgambarini.github.io/Journal/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rgambarini.github.io/Journal/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-06-02T15:16:50+00:00</updated><id>https://rgambarini.github.io/Journal/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Do Digital Monkeys Dream of Electronic Sonnets?</title><link href="https://rgambarini.github.io/Journal/journal/2023/Do-Digital-Monkeys-Dream-of-Electronic-Sonnets/" rel="alternate" type="text/html" title="Do Digital Monkeys Dream of Electronic Sonnets?"/><published>2023-05-28T00:00:00+00:00</published><updated>2023-05-28T00:00:00+00:00</updated><id>https://rgambarini.github.io/Journal/journal/2023/Do%20Digital%20Monkeys%20Dream%20of%20Electronic%20Sonnets</id><content type="html" xml:base="https://rgambarini.github.io/Journal/journal/2023/Do-Digital-Monkeys-Dream-of-Electronic-Sonnets/"><![CDATA[<h2 id="what-is-information">What is Information?</h2> <p style="text-align: justify;">We encounter information in various forms, such as data entries on an Excel sheet, news reports, or social media posts. This information can be straightforward or intricate, based on facts or personal opinions, and can be either true or false. Information is the currency we use to exchange knowledge, and as the saying goes, knowledge is power. The information serves as the raw material that powers our understanding.</p> <blockquote> <p>What is the mathematical value of information?</p> </blockquote> <p style="text-align: justify;">Information theory is a field of applied mathematics that focuses on how we measure, store, and communicate information. <d-cite key="cover1999elements"></d-cite> It helps us answer fundamental questions about how information works. The science of information theory was born from the groundbreaking work of pioneering scientists like <a href="https://en.wikipedia.org/wiki/Claude_Shannon">Claude Shannon</a>, <a href="https://en.wikipedia.org/wiki/John_von_Neumann">John von Neumann</a>, and <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a> in the 20th century. <d-cite key="shannon1948mathematical"></d-cite> <d-cite key="von1956probabilistic"></d-cite> <d-cite key="turing2014enigma"></d-cite> These scientists created laws to regulate how we transmit, compress, decompress, and handle errors in the information. <d-cite key="wicker1994error"></d-cite> To measure information, they decided to use bits, which are short for binary digits. <d-cite key="nyquist1924certain"></d-cite> <a href="https://en.wikipedia.org/wiki/Bit">Binary digits</a> represent only two fundamental values, 0 and 1, and are crucial to electronic circuits’ basic structure. These digits can help us distinguish between two states, such as high and low voltage levels, which can represent the two binary states of 0 and 1. <d-cite key="seggelmann2011strategies"></d-cite></p> \[1 \qquad \qquad 0\] \[Yes \qquad \quad No\] \[True \quad \quad False\] \[. \qquad \qquad -\] \[\uparrow \qquad \qquad \downarrow\] \[\leftarrow \qquad \qquad \rightarrow\] <div class="caption"> <em>Binary numbers can be used in different ways. Such as expressing directions, simple answers, and even as an alternative representation of morse code.</em> </div> <p style="text-align: justify;">This standard was not decided haphazardly. The binary values of 1 and 0 could be used to represent simple logical operations, and it is this versatility that allowed computers to tackle a wide array of problems<d-cite key="ralston1993encyclopedia"></d-cite>.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/Information_art-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/Information_art-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/Information_art-1400.webp"/> <img src="/Journal/assets/img/Monkeys/Information_art.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">In the fields of physics and cosmology, information has become a crucial tool to explore the underlying principles of the universe. <d-cite key="aaronson201612"></d-cite> Physicists use the ‘bit’ as the most fundamental building block that can be defined. <d-cite key="lloyd2002computational"></d-cite> Some physicists have proposed that the universe itself may operate like a giant computer, processing vast amounts of information through physical processes. <d-cite key="lloyd2002computational"></d-cite> The recent debate around Hawking radiation exemplifies the importance of information in physics. <a href="https://en.wikipedia.org/wiki/Hawking_radiation">Hawking radiation</a> suggests that black holes emit particles, which carry away information about the black hole’s internal state. <d-cite key="hawking1976breakdown"></d-cite> One could argue that information theory represents the study of the very foundations of nature. <d-cite key="aaronson201612"></d-cite></p> <hr/> <h2 id="the-infinitely-small-possibilities">The Infinitely Small Possibilities</h2> <p style="text-align: justify;">The <a href="https://en.wikipedia.org/wiki/Infinite_monkey_theorem">infinite monkey theorem</a> is a popular thought experiment that shows the reality of minuscule probabilities. It considers the possibility that if you had a monkey use a typewriter, and the monkey could hit random keys for an infinite amount of time, that eventually he would create a perfect copy of William Shakespeare’s complete works. <d-cite key="gowers2008princeton"></d-cite> Mind you, there is nothing special about The Bard’s timeless works. The same could be said about any text that ever existed. This room’s floor might as well be filled with every text ever conceived, every book that will be eventually written, and even your Sunday shopping list. This certainly doesn’t seem realistic, does it? And it is not. At least not in this universe.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/roomFullofPapers-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/roomFullofPapers-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/roomFullofPapers-1400.webp"/> <img src="/Journal/assets/img/Monkeys/roomFullofPapers.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">For now, <a href="https://rgambarini.github.io/Journal/journal/2023/Journey-to-the-Center-of-Infinity/">infinity remains a mathematical concept</a>, far removed from the reality of physics. <d-cite key="brouwer1975intuitionism"></d-cite> Even though the probability of a monkey typing a Shakespearean sonnet correctly is infinitesimally small, games of chance offer better illustrations of this idea. For instance, the <a href="https://en.wikipedia.org/wiki/Powerball">US Powerball</a> is one of the most famous lottery games worldwide. Considering that it holds the record for the largest prize ever awarded in the lottery, who wouldn’t want to have the prize-winning numbers? <d-cite key="grote2013economics"></d-cite> The game is as follows:</p> <p style="text-align: justify;">In the <a href="https://www.flalottery.com/exptkt/pwrball-odds.pdf">US Powerball</a>, five balls are chosen at random from a pool of 69 numbered balls. Additionally, one red Powerball is chosen from a set of 26 numbered balls. If you correctly guess some of the numbers, you can win a portion of the prize money. However, you need to guess all the numbers in the correct order to win the grand prize.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/powerball-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/powerball-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/powerball-1400.webp"/> <img src="/Journal/assets/img/Monkeys/powerball.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>A simple representation of how the lottery numbers are drawn. Each white ball is uniquely numbered from 1 to 69 and each red Powerball is uniquely numbered from 1 to 26. During the picking, a mechanism will propel one of the balls outside of the box to ensure a random pick. Lovely lady announcing the numbers not included.</em> </div> <p style="text-align: justify;">How likely are you to win the jackpot? First, let’s consider the total number of possible combinations that might occur in this game. <a href="https://en.wikipedia.org/wiki/Combinatorics">Combinatorics</a> is a branch of mathematics that deals with the study of counting and arranging objects or elements. In this case, we only care about how many different \(r\) arrangements we can get from \(n\). When \(r = 5\) and \(n = 69\) the solution is as follows:</p> \[C(r,n) = \frac{n!}{r!(n-r)!} = \frac{69!}{5!(69-5)!} = \frac{69 \times 68 \times 67 ... \times 1}{5 \times 4 ... \times 1 \times 64 \times 63 ... \times 1} = 11,238,513\] <div class="caption"> <em>Reminder that the factorial of a number would be a series of operations in a number multiplied by the same number minus one until it's multiplied by 1 $$a! = a \times (a - 1) \times ... \times 1 $$</em> </div> <p style="text-align: justify;">For the single red Powerball, it is as simple as:</p> \[C(r,n) = \frac{n!}{r!(n-r)!} = \frac{26!}{1!(26-1)!} = \frac{26 \times 25!}{1 \times 25!} = 26\] <p style="text-align: justify;">So we are left to choose between \(11,238,513\) (known as \(N\)) possible combinations of numbers for the white balls, and 26 different numbers for the red Powerball. To win the grand prize we need to determine one single combination of both. What is the probability that we do this? This ends up being a simple calculation since we know that there is only 1 (or \(n\)) possible combination that ends up being the winning attempt:</p> \[P = \frac{n}{N} = \frac{1}{11,238,513} \times \frac{1}{26} = \frac{1}{292,201,328}\] <div class="caption"> <em>A 1 in 292,201,328 chance of winning certainly feels impossible. Knowing this, you should ask yourself a single question next time you are going to buy a lottery number</em> <p> <em>Do I feel lucky</em><d-footnote>Well do you, punk?</d-footnote> </p> </div> <p style="text-align: justify;">To calculate the probability of success for the infinite monkey theorem, we need to consider more than just the 26 letters of the English alphabet. We assume that the monkey has access to a keyboard that includes uppercase and lowercase letters, numbers, punctuation symbols, and other symbols necessary for a book (such as spaces and new lines). Altogether, this gives us about 88 inputs to work with.</p> \[P = \frac{n}{N} = \frac{1}{88} = 0.0113636... \approx 1.14\%\] <div class="caption"> <em>The probability of each individual input</em> </div> <p style="text-align: justify;">The Gutenberg <a href="gutenberg.org">project</a> is a repository that provides an extensive source of books that have way past expired their copyright rights. Using this resource we can acquire a copy of William Shakespeare’s complete works in .txt format. The number of characters in “<a href="https://www.gutenberg.org/ebooks/100">The Complete Works of William Shakespeare</a>” is about 5,480,868. For the monkey to write the full text in a single sitting becomes vanishingly small:</p> \[P(n, N) = \frac{n}{N} = (\frac{1}{72})^{5,480,868} = 10^{-10^{7.007739000088917}}\] <p>This probability increases on every attempt. This implies that the event eventually happens, just that no one would be alive to confirm it:</p> \[P_{\notin}(x) = (1 - P)^{x}\] \[P(x) = 1 - (1 - P_i)^{x} \approx 1\] \[P(x) = 1 - (1 - 10^{-10^{7.007739000088917}})^{x} \approx 1\] <div class="caption"> <em>Starting from the complement rule, which states that the probability of an event occurring is equal to 1 minus the probability of the event not occurring, we can find the attempt x where the event is most likely.</em> </div> <hr/> <h2 id="down-to-monkey-business">Down to Monkey Business</h2> <p style="text-align: justify;">The infinite monkey theorem proposes the idea that unlikely events can occur. This concept has been the subject of many simulations and studies that try to replicate this phenomenon. <d-cite key="banerji2013notion"></d-cite> However, what is more interesting is understanding the underlying mechanisms that make this possible. The theory suggests that highly ordered structures can emerge from chaos<d-cite key="gowers2008princeton"></d-cite>. While we won’t attempt to simulate the entire problem, we will conduct a scenario that should produce some profound results.</p> <p style="text-align: justify;">To build our simulation, we will use computers that will act as digital counterparts to our monkeys. This way, we can accelerate the typing process by having the computer do the same work of multiple monkeys in tandem. Additionally, we need to specify the way that our ‘digital monkeys’ will output data. To get closer to theory, we also need to recreate the method in which monkeys would input characters. For this purpose, I chose the reliable <a href="https://typewriterdatabase.com/1973-ibm-selectric-721.19605.typewriter">1973 IBM Selectric 721</a>, as it contains all the letters and symbols that they would need.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/selectric-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/selectric-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/selectric-1400.webp"/> <img src="/Journal/assets/img/Monkeys/selectric.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">To represent each keystroke in our simulation, we will generate a random binary number that will indicate an input. A 7-bit binary number gives us enough combinations to represent every character on the Selectric typewriter. Binary numbers have the advantage of being easy to quantify in terms of digital size. Using a typical encoding like <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> or <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a>, each character has a size of one byte. This means that each input to the typewriter has a size of 7 bytes (one byte per bit), and each output from the typewriter (representing a keystroke) has a size of 1 byte. To generate truly random inputs, we use the <a href="https://github.com/jedisct1/libsodium">libsodium library</a> to create cryptographically secure random bytes.</p> <table style="border-collapse:collapse;border-color:#ccc;border-spacing:0;border-style:solid;border-width:1px" class="tg"><thead><tr><th style="background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal"></th><th style="background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">a</th><th style="background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">b</th><th style="background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">c</th><th style="background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">...</th><th style="background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">-</th><th style="background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">=</th></tr></thead><tbody><tr><td style="background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;font-weight:bold;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">7-bit Binary</td><td style="background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">1100001</td><td style="background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">1100010</td><td style="background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">1100011</td><td style="background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">...</td><td style="background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">0101101</td><td style="background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">0111101</td></tr></tbody></table> <div class="caption"> This is our translation between our binary inputs and the output from our virtual typewriter. </div> <p style="text-align: justify;">Now that we have our tools, let’s start defining our workspace. Until the machines rise against us, we can use any different number of ‘digital monkeys’ for any amount of time. Unfortunately, we still have to consider the computational cost that would allow our computer to do the work. <a href="https://colab.research.google.com">Google Colab</a> is a free, cloud-based platform for running and sharing code. Although predominantly used to run Python scripts, we can use the instances provided by Colab as a computer that runs processes in the cloud. These cloud computers, like any computer, have a limit on what they can do simultaneously. Additionally, since this is a dynamic environment (resources are dependent on the number of users using the service), we cannot easily know the number of monkeys that we can assign to this task. We can try to get an estimate of the optimal number of ‘digital monkeys’ that we can have working in <a href="https://en.wikipedia.org/wiki/Parallel_computing">parallelism</a>. To do so, we can set a loop that increases the number of processes for a directly proportional set of time, and then look at the average time it takes for the process to finish.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/limit_test-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/limit_test-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/limit_test-1400.webp"/> <img src="/Journal/assets/img/Monkeys/limit_test.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>This figure shows the average time it required an individual process to complete its designated task when multiple processes are executed in parallel.</em> </div> <p style="text-align: justify;">At low levels of parallelism (e.g. 100 processes), the program may be able to efficiently utilize the available hardware resources without encountering bottlenecks or fighting for shared resources. At high levels of parallelism (e.g. 500 processes), the program may start to encounter hardware limitations such as network bandwidth, disk I/O, or memory bandwidth that limit the overall performance of the program. Not a great look at how well-optimized this simulation is, but good enough to get the data that we need. We will use 120 for our number of processes as this is the minimum value in our line of best fit.</p> <p>In order to determine how many words we produce we need to use a dictionary. This is not your typical dictionary, as we do not require any definitions in this simulation. <d-footnote>Although the complexity of the definition could very well be an additional variable, we don't need it right now to perceive a trend</d-footnote> This dictionary will only show us words that could be used in the English language. If money is not a problem we could use the <a href="https://www.collinsdictionary.com/dictionary/english">Collins English Dictionary</a> as a base as it includes over 722,000 words. Sadly, money <em>is</em> a problem. A free alternative that is very commonly used in these sorts of problems is <a href="https://wordnet.princeton.edu">WordNet</a>, which is a free lexical database that includes a respectable 155,000 words and phrases. Thankfully, <a href="http://infochimps.org">InfoChimps</a> provides a sufficient dictionary with 479k English words and is freely available through a <a href="https://github.com/dwyl/english-words">GitHub repo</a>.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/monkey_biz-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/monkey_biz-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/monkey_biz-1400.webp"/> <img src="/Journal/assets/img/Monkeys/monkey_biz.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <hr/> <h2 id="all-the-worlds-a-monkeys-stage">All the World’s a Monkey’s Stage</h2> <p style="text-align: justify;">At the end of our simulation, we managed to produce 3.7 Gbs of text in 156 hours with the help of our 120 digital monkeys. So what does this look like? Let’s examine the overall dataset:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/initial-data-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/initial-data-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/initial-data-1400.webp"/> <img src="/Journal/assets/img/Monkeys/initial-data.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Percentage of word length in our data. Crosses represent the number of instances of the given word length divided by the total number of characters in our data. The curve shows the relative trend that this analysis follows.</em> </div> <p style="text-align: justify;">This simply won’t do. We are currently including every single character in the data, regardless if it is significant or not. We need to establish criteria for tagging words in our dataset. Although the letter ‘a’ is a perfectly reasonable word, it leaves too much to interpretation regarding how much ‘information’ it provides in the text. We can’t be sure of what is a random input or what would be a significant word. So for this analysis, we will simply ignore any words that are made of a single character. <d-footnote>Feel free to rant on this decision down below.</d-footnote></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/zoomed-data-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/zoomed-data-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/zoomed-data-1400.webp"/> <img src="/Journal/assets/img/Monkeys/zoomed-data.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">Our analysis shows that there is a \(15.915\)% chance that a two-letter word shows up in our dataset, and that every additional character decreases the likelihood significantly as the word length increases. It is always wise to make sure that our results make sense. What is the expected length of words in our dataset when we analyze the distribution of word lengths in our dictionary?</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/dictionary-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/dictionary-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/dictionary-1400.webp"/> <img src="/Journal/assets/img/Monkeys/dictionary.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Our dictionary contains 479k English words which include 20+ character words that are not significant during this study.</em> </div> <p style="text-align: justify;">Based on this graph alone, it might be logical to think that ~\(10\) letter words should be more prevalent in our data. To resolve this inconsistency, we must return to our probability calculations. We must remember that every consecutive character is confined by a probability. If we want a \(6\) letter word and we currently have \(88\) different options, then every input to our data is restricted by the distribution of this probability:</p> \[(\frac{1}{88})^{6} = \frac{1}{88} \times \frac{1}{88} \times ... \times \frac{1}{88} = \frac{1}{464,404,086,784}\] <p style="text-align: justify;">Now that we have the probabilities in place, how does it help us determine the amount of information contained? Information theory provides us with a method to quantify the amount of information contained in a file using the concept of entropy. The mere mention of <a href="https://en.wikipedia.org/wiki/Entropy">entropy</a> can cause anxiety to most scientists. It is a complex and abstract concept that is central to several fields of science. It has multiple meanings, different interpretations, and a wide array of formulations. More than anything, people find it non-intuitive. In this case, entropy measures the amount of uncertainty or randomness in our data.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/entropy-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/entropy-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/entropy-1400.webp"/> <img src="/Journal/assets/img/Monkeys/entropy.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">A file contains more information if the data is more unpredictable, according to the fundamental principle of using entropy to quantify information. So entropy can become our measurement of how much information there is in a file. Information entropy is calculated by identifying all possible outcomes or symbols that can appear in a file. Symbols may include individual characters in a text file or individual bits in a binary file, among other possibilities. The entropy of information can be calculated using the following formula:</p> \[H(p_i) = -Σ \enspace p_i \enspace log_2 \space p_i\] <p style="text-align: justify;">Where \(H\) is the entropy of information, \(p_i\) is the probability of symbol \(i\) occurring, and \(log_2\) is the base-2 logarithm.</p> <p style="text-align: justify;">Let’s consider the entropy of information for “The Complete Works of William Shakespeare” first. After filtering out all the copyright and index contents, we are left with 959,976 words.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/shakespeare_data-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/shakespeare_data-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/shakespeare_data-1400.webp"/> <img src="/Journal/assets/img/Monkeys/shakespeare_data.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Probability of word length in "The Complete Works of William Shakespeare".</em> </div> <p style="text-align: justify;">Calculating the entropy requires us to define a probability distribution that a word of a particular length would be found in the file:</p> \[p_i = \frac{\text{Number of instances}}{\text{Total number of words}}\] \[\qquad\] \[H(p_i) = -Σ \enspace p_i \enspace log_2 \space p_i = 2.839 \text{bits}\] <p style="text-align: justify;">Performing the same calculation to our simulation data we get that the entropy of information based on word length is \(1.242\) bits, which is quite strange. Why would we get a lower entropy when the creation of this data has been completely random? The definition of entropy should be the amount of randomness in our data. The entropy we got from our simulation is not a mistake. Claude Shannon calculated the conditional entropy of an English text based on letter frequencies, but the method can be adapted to word frequencies as well. Shannon found that the entropy per letter of English text was about \(2.3\) bits. <d-cite key="shannon1951prediction"></d-cite> This analysis assumes that the letters or words in the text are independent and identically distributed. However, in natural language, there are often patterns and correlations between words, which can increase conditional entropy. This corresponds to an average conditional entropy of about \(11.82\) bits per word according to Shannon.</p> <p style="text-align: justify;">Keep in mind, we’re not dealing with a random sequence of words in Shakespeare’s writings. Sentences have a predefined structure that goes beyond simple grammatical rules. Sometimes you can even predict a statement before it _____. <d-footnote>ends</d-footnote> The same could be said about the structure of words.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/wordle-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/wordle-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/wordle-1400.webp"/> <img src="/Journal/assets/img/Monkeys/wordle.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Begrudgingly revealing my first-word strategy.</em> </div> <p style="text-align: justify;">The online game <a href="https://www.nytimes.com/games/wordle/index.html">Wordle</a> became a massive hit in the year 2021. It challenges a player to guess a five-letter word in six attempts and reveals feedback on which letters are correct, incorrect, or in the correct position. Naturally, we start by choosing a word that eliminates a significant number of vowels or maybe very common consonants. With the given feedback, we can correctly guess our words in as little as two attempts. <d-footnote>No. No one believes you got it on your first try</d-footnote> This is due to what we’ve stated regarding the ‘predictability’ of the English language. Attempting to play Wordle without any linguistic rules would be quite the challenge.</p> <p style="text-align: justify;">Introducing <a href="https://colab.research.google.com/drive/1FgIMvCSQIXEmZ5Ht2muWJ68jDcZjzQBm?usp=sharing">Random-le</a>, a game that challenges you to guess a random five-character ‘string’ in six attempts. Not impossible, but not something I’ll be winning or even attempting at all.</p> <p style="text-align: justify;">What if we were to be more strict regarding our analysis? If we were to imitate more closely the rules of language, then the entropy in our analysis should resemble those found in standard texts. To illustrate how a more meticulous analysis should lead us closer to Shannon’s results, let’s do one final calculation. We did not consider the effect that cases would have on the readability of the file. Meaning that so far, ‘Hello World’ and ‘helLo wORlD’ are the same. To rectify this, let’s consider ‘penalizing’ the word count for every mistake in the word. Meaning that ‘enTRopy’ would be counted as a \(5\) letter word instead of \(7\). For example, the probability of finding a two-letter word is now \(12.227\)% instead of the previous \(15.915\)%. By applying additional rules, we’ve increased the entropy of information based on word length to \(1.328\) bits. Which inches us closer to the entropy found in Shannon’s work and Shakespeare’s writings.</p> <hr/> <h2 id="where-art-thou-my-entropy">Where art thou my Entropy?</h2> <p style="text-align: justify;">Originally, the word “entropy” was coined by German physicist Rudolf Clausius in 1865. <d-cite key="clausius1879mechanical"></d-cite> It is derived from the Greek words “en,” meaning “in,” and “tropos,” meaning “turn” or “transformation”. <d-cite key="prigogine1987meaning"></d-cite> Clausius used the term to describe a measure of the amount of energy in a system that is no longer available to do useful work. This definition is still valid, particularly for large systems, but when physicists refer to the entropy of a system they talk about a measurement of how much of the system we are not sure of. <d-cite key="jaynes1957information"></d-cite></p> <p style="text-align: justify;">This measurement helps us understand the disorder or randomness of a system, and it increases as the system becomes more disordered. Imagine a box of magic bouncing balls. They’re magical in the way that they never lose their momentum. Meaning that once they start bouncing, they can’t stop unless we manually set them in stasis. Likewise, they won’t be able to start moving without our intervention. We start with every ball perfectly at rest. We would always be able to easily determine each ball’s position and velocity (x, 0). Our box contains no uncertainty, no randomness, and no entropy.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/bouncing_balls-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/bouncing_balls-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/bouncing_balls-1400.webp"/> <img src="/Journal/assets/img/Monkeys/bouncing_balls.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">If we were to set one of our balls in motion, then we end up increasing the entropy of the box slightly. Now it’s going to be more challenging to define the position and velocity of every ball. We’ve added some uncertainty to our system. The same occurs by putting every ball in our box in motion. The entropy rises directly by increasing the number of balls and their speed. This same concept can be applied to a system with gas. Where every bouncing ball can be replaced with a molecule. The entropy in this system can be calculated, and from that, properties such as temperature and pressure can be naturally inferred.</p> <p>Is Shannon’s entropy of information the same as this? Entropy in statistical mechanics and information theory are both measures of disorder or uncertainty, and they both have the same mathematical form when expressed in terms of probabilities. The Boltzmann distribution is a probability distribution that gives the probability of a system being in a certain state as a function of that state’s energy and the temperature of the system. <d-cite key="maxwell1878tait"></d-cite></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/boltzmann-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/boltzmann-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/boltzmann-1400.webp"/> <img src="/Journal/assets/img/Monkeys/boltzmann.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>This figure shows the probability of a system being in a certain state as a function of that state’s energy and temperature, according to the Boltzmann distribution1. The x-axis represents the energy of the state and the y-axis represents the probability.</em> </div> <p style="text-align: justify;">Energy and information are both subject to the same fundamental constraints of thermodynamics, and they can be seen as two different forms of entropy. There is a connection between bits of information and bits of energy, where the energy content of a physical system is related to the amount of information that it can store or process. The entropy of a black hole can be thought of as the amount of information that is hidden behind the event horizon, beyond the reach of any observer outside the black hole. The energy of a black hole can be converted into information, or vice versa, through the process of Hawking radiation. <d-cite key="susskind2004introduction"></d-cite></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Monkeys/water_black-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Monkeys/water_black-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Monkeys/water_black-1400.webp"/> <img src="/Journal/assets/img/Monkeys/water_black.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">You might be wondering the difference between these ‘bits’ from entropy and the ‘bits’ encoded in the 3.7 Gbs of data we have generated. <d-footnote>1 GB = 1,073,741,824 bytes * 8 bits/byte = 8,589,934,592 bits</d-footnote> The bits in a file size refer to the amount of storage required to represent the contents of a file, while the bits in the entropy of information refer to the amount of uncertainty or randomness in a given set of information. That being said, they both refer to the same unit value. The significant difference in these values suggests that the contents contain a large amount of redundancy.</p> <blockquote> <p><em>Tomorrow and tomorrow and tomorrow <br/>Creeps in this petty pace from day to day <br/>To the last syllable of recorded time, <br/>And all our yesterdays have lighted fools <br/>The way to dusty death. Out, out, brief candle! <br/>Life’s but a walking shadow, a poor player <br/>That struts and frets his hour upon the stage <br/>And then is heard no more. It is a tale <br/>Told by an idiot, full of sound and fury, <br/>Signifying nothing</em> <d-footnote>In many theatre groups, the implication of redundancy might earn you a beating.</d-footnote></p> </blockquote> <p style="text-align: justify;">By this measure, a highly compressed cat video contains an entropy much larger than its file size. This video would have very little redundancy in its data. But the significance of the information in The Bard’s work is inherently more valuable. <d-footnote>Again, feel free to rant in regards to this statement down below.</d-footnote> This doesn’t change our definition of information but instead sheds some light on what we mean by entropy.</p> <p style="text-align: justify;">Struggling with the concept of entropy might as well be added as one of the laws of physics. But its importance is so profound that it incites a desire to learn more about it. The results of this simulation should show you that the meaning of this physical property is much more complex than what Clausius and his contemporaries originally proposed. Hopefully reading this didn’t leave you too confused, but I also hope that it gave you the desire to understand more.</p> <p><a href="https://github.com/RGambarini/Journal/blob/master/assets/Notebooks/Infinite_Monkeys_Simulation.ipynb">Infinite Monkey Simulation Python Notebook</a></p> <p><a href="https://github.com/RGambarini/Journal/blob/master/assets/Notebooks/Infinite_Monkeys_Analysis.ipynb">Infinite Monkey Analysis Python Notebook</a></p> <p><a href="https://github.com/RGambarini/Journal/blob/master/assets/Notebooks/Shakespeare_Analysis.ipynb">Shakespeare Text Analysis Python Notebook</a></p>]]></content><author><name>Roberto A. Gambarini</name></author><category term="Information-Theory"/><category term="Statistical-Mechanics"/><category term="Computer-Simulation"/><summary type="html"><![CDATA[The curious birth of information from randomness]]></summary></entry><entry><title type="html">The Multiverse of Madness</title><link href="https://rgambarini.github.io/Journal/journal/2023/The-Multiverse-of-Madness/" rel="alternate" type="text/html" title="The Multiverse of Madness"/><published>2023-05-24T00:00:00+00:00</published><updated>2023-05-24T00:00:00+00:00</updated><id>https://rgambarini.github.io/Journal/journal/2023/The%20Multiverse%20of%20Madness</id><content type="html" xml:base="https://rgambarini.github.io/Journal/journal/2023/The-Multiverse-of-Madness/"><![CDATA[<h2 id="in-another-time-in-another-place">In another time. In another place</h2> <p style="text-align: justify;">Have you ever wished you could go back in time and change a decision you made? Many of us have fantasized about how our lives could have been different if we had made different choices. What if we were working somewhere else? What if we were married to someone else? What if we lived in a different part of the world? While this is just our little fantasy, it’s something that many people think about.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/back-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/back-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/back-1400.webp"/> <img src="/Journal/assets/img/Multiverse/back.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Then who's vice-president, Jerry Lewis? I suppose Jane Wyman is the First Lady!</em> <d-footnote> Back to the Future logo is a trademark of Universal City Studios LLC. Downloaded from freebiesupply.com </d-footnote> </div> <p style="text-align: justify;">The idea of parallel universes dates back so far that it presents the idea that it was never exclusive to superhero movie sequels. It has been around for centuries and may have stemmed from humanity’s desire for exploration or a more ‘fantastic’ reality. <a href="https://en.wikipedia.org/wiki/Anaximander">Anaximander</a>, a philosopher who lived in present-day Turkey in the 6th century BCE, proposed the existence of an infinite number of worlds. <d-cite key="kahn1960anaximander"></d-cite> To him, the universe was eternal and expanded endlessly without reservations. Much like walking from Marseille to Athens, a new world always seems to pop out behind the horizon. By this metric, <em>long time ago in a galaxy far far away</em>, there’s a perfect copy of Earth where Anaximander worked on this same theory. These beliefs were very controversial at the time. You should remember that it predated <a href="https://en.wikipedia.org/wiki/Copernican_heliocentrism">Copernicus’s heliocentric model</a> by 2000 years.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/heliocentric-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/heliocentric-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/heliocentric-1400.webp"/> <img src="/Journal/assets/img/Multiverse/heliocentric.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>1520-41 CE illustration of the heliocentric view of our solar system</em> <d-footnote> "The heliocentric view of our solar system from ‘De Revolutionibus Orbium Coelestium’ by Nicolaus Copernicus. Downloaded from worldhistory.org"</d-footnote> </div> <p style="text-align: justify;">A recent analysis has proposed that the idea of parallel universes is far from fiction, but that it also requires a proper definition of ‘parallelism’. <a href="https://en.wikipedia.org/wiki/Max_Tegmark">Max Tegmark</a>, a Swedish-American physicist and cosmologist, has proposed a framework for categorizing different levels of the multiverse. <d-cite key="tegmark2003multiverse"></d-cite> In addition, he details a framework for categorizing different levels of the multiverse. Tegmark’s theory, like almost every new theory in physics, has been the subject of debate and controversy within the scientific community. <d-cite key="ellis2011scientific"></d-cite> These ideas rely on proven or widely accepted concepts but cannot be accepted as a complete theorem. Instead, the categories that Tegmark has proposed detail definitions regarding acceptable propositions of a multiverse. Each ‘level’ presents a reality that neglects a known constraint of our standard universe. So each subsequent level becomes a more controversial representation of our reality.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/tegmark-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/tegmark-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/tegmark-1400.webp"/> <img src="/Journal/assets/img/Multiverse/tegmark.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Max Tegmark</em> <d-footnote> https://en.wikipedia.org/wiki/Max_Tegmark</d-footnote> </div> <hr/> <h2 id="level-i-an-extension-of-our-universe">Level I. An extension of our universe</h2> <p style="text-align: justify;">The first level of the multiverse theory is a proper definition of Anaximander’s proposal. In an infinite universe, every possible configuration can be eventually reached. Although we have previously discussed the limitations of infinity in physics, our universe can technically be described as infinite. <d-cite key="linde2003inflation"></d-cite> Our universe expands at a rate at which we would never actually see the end of it.</p> <p style="text-align: justify;">At the macroscopic scale, we use statistical mechanics to categorize the behavior of large collections of particles as ensembles. This means that any configuration of position and velocity from the particles is equally likely. <d-cite key="pathria2011statistical"></d-cite> Consider a container that holds a gas such as Neon or Helium. If we record the particles’ position and velocity over time, we will see that each configuration is equally likely to occur. Even the ones that are seemingly impossible, such as a configuration that places all atoms in a corner of the container. Similarly, consider our observable universe as one of these ‘unlikely’ configurations. If our universe is truly ‘virtually’ infinite, then somewhere a perfect copy will arise.</p> <p style="text-align: justify;">However, energy cannot be created out of nothing. <d-cite key="carroll2004spacetime"></d-cite> At some point, the components that make up our universe will react until becoming inert and depleted. This is known as the “heat death of the universe”. <d-cite key="pathria2011statistical"></d-cite> Personally, a more appropriate term is the “end of heat transfer in the universe”, but it doesn’t have the same ring to it.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/heatdeath-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/heatdeath-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/heatdeath-1400.webp"/> <img src="/Journal/assets/img/Multiverse/heatdeath.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">In simpler terms, imagine being trapped in a room that is continuously expanding. The room has a considerable number of resources to ensure your survival, such as water and food. The room’s expansion is so fast that you would never see the walls of the room. Even if you had enough food and water to last you decades, it will eventually run out. This is the case within our observable universe. Even if it was endless, there’s a static quantity of ‘stuff’ inside of it.</p> <hr/> <h2 id="level-ii-different-constants">Level II Different constants</h2> <p style="text-align: justify;">Our universe requires a set of unchangeable values that define physics. These are much more fundamental that the radius of an atom or the acceleration of gravity. Many of the things that we call ‘constants’ are only applicable on Earth or are the subject of some broad approximation. \(9.8 \space \frac{m}{s^2}\) is a value that we assign to the acceleration that an object feels <em>towards Earth</em>. This value won’t serve us much if we were stranded on some anomalous planet or deep in the vacuum of space.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/space-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/space-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/space-1400.webp"/> <img src="/Journal/assets/img/Multiverse/space.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">As far as we know, there are only three fundamental constants that are obeyed strictly throughout the universe: <d-cite key="susskind2008black"></d-cite></p> <ul> <li>The maximum speed any object has an upper limit which is defined by the speed of light \(c = 299,792,458 \space \frac{m}{s}\)</li> <li>Objects attract each other with a force that is proportional to the product of each object’s mass and a gravitational constant. We call this the Gravitational’s constant \(G = 6.67430(15)×10^{−11} \frac{m^3}{kg⋅s^2}\)</li> <li>The uncertainties of an object’s position and momenta cannot be smaller than Planck’s constant \(h = 6.62607015 × 10^{-34} \frac{J}{Hz}\)</li> </ul> <p style="text-align: justify;">These limitations are supreme, and they have been since the birth of our universe. But consider the possibility that during the birth of our universe, these constants change ever so slightly. <d-cite key="linde2003inflation"></d-cite> The most likely lifetime of the universe is very similar to our very own. An incredible beginning, a storied and complex existence, and an unsurprisingly dull finale.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/life-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/life-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/life-1400.webp"/> <img src="/Journal/assets/img/Multiverse/life.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">An alternative theory, which is much more controversial, presents our universe as cyclic. <d-cite key="steinhardt2002cyclic"></d-cite> The universe follows an eternal series of oscillations, each beginning with a Big Bang and ending with a Big Crunch. <d-cite key="frampton2011cyclic"></d-cite> It expands for some time before the gravitational attraction of matter causes it to collapse back in and undergo a bounce.</p> <p style="text-align: justify;">During these ‘bounces’, the constants that define our current universe might change. Give rise to different types of matter and energy, allow for faster-than-light travel, or maybe even make space exploration impossible. In some variations matter and energy might be impossible, creating a completely void universe. <d-cite key="linde2003inflation"></d-cite></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/cyclic-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/cyclic-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/cyclic-1400.webp"/> <img src="/Journal/assets/img/Multiverse/cyclic.jpg" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Roger Penrose's Cyclic Universe</em> <d-footnote> https://physicsworld.com/a/inside-penroses-universe/</d-footnote> </div> <p style="text-align: justify;">Again, we end up falling back to the same problem in our Level 1 universe. Arguments that encourage the theory of a bouncing universe tend to ignore or diminish the impact of entropy. <d-cite key="guth2007eternal"></d-cite> To justify a ‘crunch’, there would have to be enough energy to contract itself. Maybe this would be likely in the early period of expansion, where there is enough energy to justify a massive recoil. But there is not enough proof that would say so.</p> <p style="text-align: justify;">There have been some reasonable attempts to justify this theory. You have to remember; we are merely at the second ‘most likely’ level of the multiverse theory. This allows theories to rely on the least amount of assumptions to provide necessary explanations. Proponents of a cyclic universe have included Albert Einstein, <d-cite key="einstein1916foundation"></d-cite> John Archibald Wheeler, <d-cite key="wheeler1964geometrodynamics"></d-cite> Sir Roger Penrose, <d-cite key="penrose2006before"></d-cite> and other giants in the world of physics. Although Einstein eventually relented to the idea of an endless universe, dark energy has provided a window that enables the justification for the missing energy required. <d-cite key="ellis2011dark"></d-cite></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/ewp-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/ewp-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/ewp-1400.webp"/> <img src="/Journal/assets/img/Multiverse/ewp.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Albert Einstein (Left), <d-footnote> https://en.wikipedia.org/wiki/Albert_Einstein </d-footnote> John Archibald Wheeler (Middle), <d-footnote> https://en.wikipedia.org/wiki/John_Archibald_Wheeler </d-footnote> and Nathan Rosen (Right) <d-footnote> https://en.wikipedia.org/wiki/Roger_Penrose </d-footnote> </em> </div> <p style="text-align: justify;">For most people, the idea of a cyclic universe is logical. We live in a world of cycles. Much of the study of Biology and Geology is made up of cyclic processes where every component is re-utilized. The problem lies with the fact that these are not perfectly conserved cycles. These have the unquestionable consequence of a rising entropy, or rather, the decrease of usable reacting components. At some point in these cycles, a perishable resource has to be expended for these cycles to continue undisturbed. This gives the impression that these cycles are endless. On the time scale of millions of years resources such as water, geothermal, and solar activity are finite.</p> <hr/> <h2 id="level-iii-the-many-worlds-interpretation">Level III The Many-Worlds Interpretation</h2> <p style="text-align: justify;">In quantum mechanics the nature of probabilistic events implies that <em>if something is allowed, it may happen, it can happen, and it will happen</em>. <d-cite key="griffiths2005introduction"></d-cite> If an event is allowed by the laws of quantum mechanics, it means that it has a non-zero probability of occurring. It’s worth noting that this statement applies to the quantum scale, but not necessarily to macroscopic objects.</p> <p style="text-align: justify;">The ‘Copenhagen interpretation’ is the most widely accepted explanation of probabilistic events in quantum mechanics. <d-cite key="griffiths2005introduction"></d-cite> According to this theory, all possible outcomes of a quantum event exist simultaneously before measurement. Once a measurement is made, the probabilities collapse into a single event. This can lead to seemingly paradoxical situations, such as an arrow appearing to be pointing left and right at the same time before it is observed.</p> <p style="text-align: justify;">One of the alternative theories regarding this behavior is the ‘Many-Worlds interpretation’ from <a href="https://en.wikipedia.org/wiki/Hugh_Everett_III">Hugh Everett III</a>. <d-cite key="everett1957relative"></d-cite> This theory proposes that every possible outcome of a quantum measurement occurs in a separate, parallel universe. Each state corresponds to a separate universe, and the act of measurement causes the observer to enter one of the many parallel universes.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/hugh-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/hugh-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/hugh-1400.webp"/> <img src="/Journal/assets/img/Multiverse/hugh.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Hugh Everett III</em> <d-footnote> https://en.wikipedia.org/wiki/Hugh_Everett_III</d-footnote> </div> <p style="text-align: justify;">These parallel instances would also have the capacity to obey different physical constants. Instead of being subjected to the theory of a cyclic universe, the multiple worlds interpretation relies on an alternative view of a proven quantum physics phenomenon.</p> <p style="text-align: justify;">However, the many-worlds interpretation is considered untestable and therefore unscientific. <d-cite key="fuchs2002quantum"></d-cite> It presents a situation in that measuring a quantum property results in multiple ‘unmeasurable’ alternatives. The parallel universes being unmeasurable dictates that they cannot be tested or proven. This makes it less likely that it is correct, especially considering how abstract it seems. Occam’s Razor, a principle in philosophy and science, suggests that the simplest explanation is usually the correct one. The many worlds interpretation could be considered an example of the other extreme of this philosophy.</p> <blockquote> <p><em> “The most outrageous explanation, even if it is the only one, cannot be possibly true.” </em></p> </blockquote> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/marbles-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/marbles-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/marbles-1400.webp"/> <img src="/Journal/assets/img/Multiverse/marbles.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <hr/> <h2 id="level-iv-ultimate-ensemble">Level IV Ultimate Ensemble</h2> <p style="text-align: justify;">The final level of Tegmark’s categorical multiverse is called the ‘ultimate’ ensemble. As stated before, each level rejects a known constraint of our standard universe. At the end of the multiverse hierarchy, we find ourselves with a multiverse that follows nothing but the laws of mathematics. <d-cite key="tegmark2008mathematical"></d-cite></p> <p style="text-align: justify;">However, doesn’t our universe already follow the laws of mathematics? Certainly, but not all of them. Some mathematical concepts, such as imaginary and transfinite numbers, have no physical representation. While they can be used to represent many physical properties, they are not used to represent real quantities.</p> <p style="text-align: justify;">Let’s make a general assumption here:</p> <blockquote> <p><em>Physics must obey mathematics, but mathematics does not encompass all of physics.</em></p> </blockquote> <p style="text-align: justify;">In this ultimate ensemble, every mathematically possible structure is conceivable in a different universe. This also encompasses all previous levels and expands on the level II multiverse theory of different physical constants. This implies that not only different values for gravity and the speed of light but also different mathematical equations could exist. In our universe, the location of an object is defined by three positional values (such as length, height, and depth) and the time at that position. Other universes might ignore that and require any number of spatial and time dimensions, or perhaps none at all.</p> <p style="text-align: justify;">Such a reality could provide relevance to theories that have a consistent mathematical basis but cannot be accepted in our world. Quantum mechanics represents the physics of small objects very well while struggling with the physics of large objects. Conversely, relativity is successful in explaining the physics of large objects but struggles with small objects. Although both fields have had success, there is still no way to reconcile them into a single theory, known as the “theory of everything.” <d-cite key="greene2000elegant"></d-cite></p> <p style="text-align: justify;">String theory was developed as an attempt to successfully combine the theories of quantum mechanics and relativity by describing fundamental particles as tiny, one-dimensional strings. The level II multiverse is consistent with string theory in which our universe is just one of many possible universes with different physical laws and constants. However, some versions of string theory propose that there could be additional, higher-dimensional objects called “superstrings” that would be acceptable at this level. <d-cite key="greene2000elegant"></d-cite> Level IV would allow for the existence of theories that involve non-Euclidean geometries, such as hyperbolic or elliptical geometries. <d-cite key="tegmark2008mathematical"></d-cite> Some could call it ‘every mathematician’s wet dream’ as it would suggest that our multiverse is the ‘ultimate playground’ for math.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Multiverse/string-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Multiverse/string-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Multiverse/string-1400.webp"/> <img src="/Journal/assets/img/Multiverse/string.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">Although some critics argue that string theory is a waste of time and resources, the potential consequences of an “Ultimate Ensemble” multiverse are considerable. String theory has been proven to be mathematically consistent. If there is a universe that respects string theory and can be correctly addressed as ‘the theory of everything’ of some universe then perhaps it could be translated to our own. If the theory works in one universe, it may be possible to adapt it to ours with some effort. <d-cite key="greene2000elegant"></d-cite> Therefore, understanding the multiverse, including the possibility of an Ultimate Ensemble, may help us unlock the mysteries of our universe and our place in it.</p> <hr/> <h2 id="theres-no-place-like-home">There’s no place like home</h2> <blockquote> <p><em> Why are there so many songs about rainbows <br/> And what’s on the other side?<br/> Rainbows are visions, but only illusions <br/> And rainbows have nothing to hide - The Frog, Kermit </em></p> </blockquote> <p style="text-align: justify;">There might be a world on the other side of the rainbow that is better than ours. Limitless energy, endless nourishment, absent of conflict. It can inspire a symbol of hope and possibility. These theories might serve as a reminder that our imagination and aspirations have the power to transcend the limitations of our present circumstances. Perhaps the desire for such a world stems from the disheartening reality of our current one.</p> <p style="text-align: justify;">The pursuit of hypothetical realities could be seen as a distraction from the responsibilities and challenges that we face in our current world. String theory has been long criticized for consuming a significant amount of resources and funding without providing concrete results or practical applications. <d-cite key="smolin2006trouble"></d-cite> If there is no way to translate string theory to our universe this could be a very costly ‘scientific dead end’.</p> <p>We could draw strength and inspiration from the vision of different worlds while remaining grounded in the reality of our current. I consider the pursuit of ideas such as string theory as an essential part of scientific discovery and progress. The basis of highly influential theories such as relativity was born from such research that was considered ‘impractical and baseless’. At the same time, we could harness the inspiration and hope that the notion of an alternate world provides to motivate us to work towards creating a better reality for ourselves and those around us.</p> <div style="text-align: center;"><iframe width="560" height="315" src="https://www.youtube.com/embed/V1bFr2SWP1I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></div>]]></content><author><name>Roberto A. Gambarini</name></author><category term="Quantum-Mechanics"/><category term="Physics"/><category term="Mathematics"/><summary type="html"><![CDATA[The 4-levels of a Multiverse Theory]]></summary></entry><entry><title type="html">Journey to the Center of Infinity</title><link href="https://rgambarini.github.io/Journal/journal/2023/Journey-to-the-Center-of-Infinity/" rel="alternate" type="text/html" title="Journey to the Center of Infinity"/><published>2023-03-26T00:00:00+00:00</published><updated>2023-03-26T00:00:00+00:00</updated><id>https://rgambarini.github.io/Journal/journal/2023/Journey%20to%20the%20Center%20of%20Infinity</id><content type="html" xml:base="https://rgambarini.github.io/Journal/journal/2023/Journey-to-the-Center-of-Infinity/"><![CDATA[<h2 id="it-is-way-bigger-than-you-think">It is way bigger than you think</h2> <p style="text-align: justify;">Think of the biggest number possible. Let me give you some help. A googolplex is the largest named number that is equal to 10 raised to the power of a googol (\(\text{googol} = 10^{100}\)). <d-cite key="kasner2001mathematics"></d-cite> To put it into perspective, there are around \(10^{80}\) atoms in the known universe. <d-cite key="davies1978tailor"></d-cite></p> \[\text{googolplex} = 10^{\text{googol}}\] <p style="text-align: justify;">Then there is Graham’s number, which was derived by Ronald Graham in the late 1970s. Graham’s number is connected to a problem in <a href="https://en.wikipedia.org/wiki/Ramsey_theory">Ramsey theory</a>, which is an area in mathematics that deals with <a href="https://en.wikipedia.org/wiki/Combinatorics">combinatorial</a> objects. <d-cite key="graham1991ramsey"></d-cite> The problem deals with finding the nodes in an <a href="https://en.wikipedia.org/wiki/Hypercube">n-dimensional hypercube</a>. Graham’s number is the upper bound of this problem. <d-cite key="griess1973schur"></d-cite> This number is so extremely large that it can’t even be written exactly. <d-cite key="graham1989concrete"></d-cite></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Infinity/White_hypercube-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Infinity/White_hypercube-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Infinity/White_hypercube-1400.webp"/> <img src="/Journal/assets/img/Infinity/White_hypercube.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Graham's Number is given by the upper bound of the following problem: Connect each pair of geometric vertices of an n-dimensional hypercube to obtain a complete graph on 2^n vertices. Color each of the edges of this graph either red or blue. What is the smallest value of n for which every such coloring contains at least one single-colored complete subgraph on four coplanar vertices?.</em> </div> <p style="text-align: justify;">You might think that this doesn’t make much sense, but in the same way that one would instinctively know that an adult has to be taller than a baby, we can also intuitively define that this upper bound is much bigger than any other quantity. So large that there is no physical analogy that I can give you. If we were to pixelate the entire universe in the <a href="https://en.wikipedia.org/wiki/Planck_units">smallest possible size</a> allowed in quantum physics, that would still only give us a mere \(10^{184}\). <d-cite key="ade2016planck"></d-cite> Which is only slightly bigger than a googolplex, and minuscule compared to Graham’s number.</p> <p style="text-align: justify;">Let’s take Graham’s number and see how much bigger we can go. We could simply have Graham’s number to the power of itself, but let’s just use an even more powerful tool. The <a href="https://en.wikipedia.org/wiki/Hyperoperation">hyper-operators</a>. The Knuth arrow notation (\(\uparrow\)) might not be a symbol you are used to, but it can represent nested exponentiation concisely. <d-cite key="knuth1984mathematics"></d-cite></p> <ul> <li>The single arrow (\(\uparrow\)) represents exponentiation:</li> </ul> \[2 \uparrow 4 = 2\times(2\times(2\times 2)) = 2^4 = 16\] <ul> <li>Two arrows, one right after another, (\(\uparrow \uparrow\)) represents tetration:</li> </ul> \[2 \uparrow\uparrow 4 = 2 \uparrow (2 \uparrow (2 \uparrow 2))= 2^{2^{2^{2}}} = 2^{16} = 65,536\] <ul> <li>Three arrows (\(\uparrow\uparrow\uparrow\)) represent pentation. As much as I want to give you the final answer to this example… it’s just ridiculously big:</li> </ul> \[2 \uparrow\uparrow\uparrow 4 = 2 \uparrow\uparrow (2 \uparrow\uparrow (2 \uparrow\uparrow 2 )) = 2 \uparrow\uparrow 65,536\] <p style="text-align: justify;">Although these hyper-operations can be powered up even further using the <a href="https://en.wikipedia.org/wiki/Conway_chained_arrow_notation">Conway chained arrow notation</a>, this should suffice for now. Now let’s try applying this tool to the already ridiculously big Graham’s number. Consider using it as a base for the pentation and itself for the pentation exponent. And just for kicks, let’s just take the factorial <d-footnote> The factorial of a number would be a series of operations in a number multiplied by the same number minus one until it is multiplied by 1 $$a! = a \times (a - 1) \times ... \times 1 $$ </d-footnote> of this:</p> \[(G \uparrow \uparrow \uparrow G)! = \text{An impossibly large number}\] <p style="text-align: justify;">Even after defining an already impossibly large number and using an operator that skyrockets it to a power of itself, this is still microscopic when compared to infinity. Graham’s number goes beyond a number that would be possible in this universe, so it is quite a challenge to comprehend the vastness of infinity. Yet we use infinity constantly in mathematics. Its use dates back to the 4th century BC with Euclid’s fundamental work in geometry and is also the basis for the development of calculus by Newton and Leibniz around 350 years ago. <d-cite key="dunham1991journey"></d-cite> Infinity’s abstract and unmeasurable essence defines many fundamental tools in mathematics, but its purely conceptual nature sparked a loud debate. This became the <em>casus belli</em><d-footnote>an act or situation that provokes or justifies a war</d-footnote> for a war that endangered the very nature of mathematics <d-footnote>If this section seems interesting to you, you can continue reading about impossibly large numbers in "The Biggest Number in the World: A Journey to the Edge of Mathematics" a book by David Darling and Agnijo Banerjee</d-footnote>.</p> <hr/> <h2 id="the-intuitionists-against-the-formalists">The Intuitionists against the Formalists</h2> <p style="text-align: justify;">What later became known as the “Foundational Crisis of Mathematics”<d-footnote> Personally the title is a bit much</d-footnote>, was a conflict between formalists and intuitionists that lasted from the late 19th century to the mid-20th century. <d-cite key="kleiner2007history"></d-cite> On one side of the ring, you had the “formalists”, who believed that infinity was just a symbol, a tool used to make calculations easier. And at the other end were the “intuitionists” who believed that infinity was an actual entity, that it existed in a Platonic sense. <d-cite key="van2002frege"></d-cite> Several factors sparked this debate, such as the discovery of applications for non-Euclidean geometry and a search for better-defined mathematical limits, but the biggest instigator was the German mathematician Georg Cantor. <d-cite key="tiles2004philosophy"></d-cite></p> <p style="text-align: justify;">Cantor is historically remembered for developing set theory, which is a branch of mathematics that studies collections of objects/numbers. <d-footnote>Names such as Real Numbers, Imaginary Numbers, and Natural Numbers might help you remember the topic</d-footnote> <d-cite key="dauben1983georg"></d-cite> Unfortunately, this superficially simple theory made Cantor <em>persona non grata</em> among many mathematicians for the consequences that it provoked. While Cantor’s mathematical proof is well-documented and relatively simple, we can neglect much of the mathematics and rely on simple <em>intuition</em>.</p> <p style="text-align: justify;">Natural numbers are a very simple set. These are always positive, whole numbers, and they do not include any fractions or decimals. Let’s take this set and put it in a box marked with the symbol \(\mathbb{N}\):</p> \[1\qquad 2\qquad 3\qquad 4\qquad 5\qquad 6\qquad \infty \rightarrow\] \[\downarrow\] \[\begin{CD} . @= . \\ @. @| @|\\ @. . @= . \end{CD}\] \[\qquad \quad \mathbb{N}\] <p style="text-align: justify;">Natural numbers are a subset of Real numbers, which also include fractions, irrational numbers, and so on. Let’s put this set on a fresh box marked with the symbol \(\mathbb{R}\):</p> \[\leftarrow -\infty\quad -3\quad -2\quad -1\quad -0.5\qquad 0\qquad 0.5\qquad 1\qquad 2\qquad 3\qquad \infty \rightarrow\] \[\downarrow\] \[\begin{CD} . @= . \\ @. @| @|\\ @. . @= . \end{CD}\] \[\qquad \quad \mathbb{R}\] <p style="text-align: justify;">Although both boxes contain an infinite amount of numbers, you could instinctively claim that there is more “stuff” in the box that has the real numbers. The set of real numbers includes natural numbers besides other sets, so the infinite number of things in one box must be bigger than the other:</p> \[\begin{CD} . @= .\\ @| @|\\ . @= .\\@. \vcenter{\hbox{$\displaystyle \mathrm{\mathbb{N}}$}} @. \end{CD} \qquad &lt; \qquad \begin{CD} . @= .\\@| @|\\ . @= .\\@. \vcenter{\hbox{$\displaystyle \mathrm{\mathbb{R}}$}} @.\end{CD}\] <p style="text-align: justify;">That leads to a strange outcome that breaks any statement in the previous section. You can quantify infinity. It’s no longer an abstract tool like functions, combinatorics, or graphs. This outraged the formalists, who could not fathom considering infinity as anything else. But it was too late. As David Hilbert, a famous German mathematician piously puts it: <d-cite key="boyer1959history"></d-cite></p> <blockquote> <p>“<em>No one shall expel us from the paradise that Cantor has created</em>”</p> </blockquote> <p style="text-align: justify;">Indeed, the genie was out of the bottle and the nature of mathematics was put into question. What is the proper role of intuition in mathematical reasoning? Is mathematics truly objective or absolute? What is the nature of similar mathematical objects? These are philosophical questions, but these led to the advancement of computer science, model theory, and theoretical physics. <d-cite key="ernest2016philosophy"></d-cite></p> <p style="text-align: justify;">However, there is no satisfying end to this story. Both the intuitionists and formalists developed multiple solutions to the apparent paradox. <d-cite key="brouwer1975intuitionism"></d-cite> All of them relied on methods to formalize the rules in mathematics, which were each successful in their regard but did not resolve this crisis independently. Formalism, intuitionism, and the theory of types all played important roles in the development of modern mathematics, and together they helped to establish a more rigorous and consistent foundation for the subject. Thanks to this new consistency, most mathematicians would agree that the paradoxes and contradictions that once plagued the subject are now resolved. <d-cite key="monk1973introduction"></d-cite></p> <p style="text-align: justify;">The questions that sparked this debate were not answered. But how could they? When mathematics itself says that they cannot be answered. In 1931, Kurt Gödel showed that any consistent axiomatic system that is powerful enough to encompass arithmetic must be incomplete. <d-cite key="smullyan1992godel"></d-cite> Incomplete meaning that there are true mathematical statements that cannot be proved or disproved within the system’s rules. <d-footnote>Who would've thought that math was such a rebel</d-footnote> A proof that shows mathematical proofs are inherently fallible and that mathematical knowledge will never be fully complete is a paradox that would depress any mathematician if considered. <d-footnote> Note that this is a currently accepted fact, but does not imply that this will always be true</d-footnote> Perhaps it is enough reason to ignore the statement and focus on something completely different. <d-footnote>It is worth noting that this only refers to a subset of the field. Many mathematicians are working towards a complete solution such as Harvey Friedman and Solomon Feferman</d-footnote> However, where there are limitations, the search for an answer might lead to other discoveries.</p> <div style="text-align: center;"><iframe width="560" height="315" src="https://www.youtube.com/embed/HeQX2HjkcNo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></div> <div class="caption"> <em>Further analysis of the conflict between the Intuitionists and the Formalists and the infinity problem was done by Veritasium in a video titled "Math's Fundamental Flaw".</em> </div> <hr/> <h2 id="infinity-in-a-physical-world">Infinity in a physical world</h2> <p style="text-align: justify;">While scientists have recently rejected philosophy towards a tendency for objective truth, the philosophical paradox of infinity can lead to some very interesting ideas. For over two thousand years, Zeno’s paradoxes have challenged our understanding of the physical world. <d-cite key="huggett2002zeno"></d-cite> In the fifth century BCE, a Greek philosopher named Zeno of Elea came up with the paradoxes. According to Zeno, the world we see around us is illusory, and only reason can reveal true reality. The purpose of his paradoxes was to illustrate the limitations of human perception and the limitations of our understanding of the physical world. Let’s look at an example of one of the paradoxes:</p> <p style="text-align: justify;">While traveling, Aristotle met the great Greek hero Achilles. <d-footnote>Fictional tale</d-footnote> Knowing his legendary renown, he knew Achilles wouldn’t back down from a simple challenge. Aristotle challenged Achilles to a footrace against a tortoise, with the rule that Achilles can only move to a position already covered by the tortoise. Considering the ridiculous assumption that he would be beaten by the small animal, Achilles accepted the challenge and gave the tortoise a considerable advantage:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Infinity/achilles1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Infinity/achilles1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Infinity/achilles1-1400.webp"/> <img src="/Journal/assets/img/Infinity/achilles1.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">Achilles laughed at the poor pace that the tortoise had, and reached its last position in no time. He would beat the animal without breaking a sweat:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Infinity/achilles2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Infinity/achilles2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Infinity/achilles2-1400.webp"/> <img src="/Journal/assets/img/Infinity/achilles2.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">Noticing the apparent frustration of Achilles not being able to overtake the tortoise, Aristotle chimed in with the reminder of the challenge “You can only move to where the tortoise has already been”.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Infinity/achilles3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Infinity/achilles3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Infinity/achilles3-1400.webp"/> <img src="/Journal/assets/img/Infinity/achilles3.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">It was too late before Achilles understood the trick. There was no way that he would be able to get ahead of the turtle even if he was twice as fast as he is now. For this, Aristotle stated the obvious fact that was forgotten “<em>In a race, the quickest runner can never over­take the slowest, since the pursuer must first reach the point whence the pursued started so that the slower must always hold a lead</em>”. <d-cite key="huggett2002zeno"></d-cite></p> <p style="text-align: justify;">While the tale might seem silly at first, it presents a questionable statement about reality. To stick to the rules, could Achilles travel an infinitely decreasing space to reach the tortoise’s last position? As British mathematician Bertrand Russell claimed, the paradox is “<em>immeasurably subtle and profound</em>”. <d-cite key="russell2022introduction"></d-cite> As we now know, the idea of an infinitely smaller space is not allowed in our current understanding of physics. While a deeper explanation would require much more involved reasoning <d-footnote>Justifiably its separate article in the future</d-footnote> we can limit the smallest size that we can measure to the Planck length<d-footnote>$$l_P = \sqrt{\frac{\hbar G}{c^3}}$$ $$l_P = \text{Planck length}$$ $$ \hbar = \text{Reduced Planck constant;}$$ $$ G = \text{Gravitational constant;}$$ $$ c = \text{Speed of light} $$</d-footnote>. By introducing the limit of our measurements to a volume of this length we can know how much smaller we are allowed to work with, and this quantity is not infinitely small. Even if we were to replace Achilles and the tortoise with perfectly tuned robots with perfectly tuned measurement devices, our measurements would start to become unmanageable way before reaching the Planck length. <d-cite key="ade2016planck"></d-cite></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Infinity/PlanckLength-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Infinity/PlanckLength-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Infinity/PlanckLength-1400.webp"/> <img src="/Journal/assets/img/Infinity/PlanckLength.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> <em>Relative scale of the Planck length. Measurements for the Atom and the proton are their respective radius. Figures for each object are not to scale</em> </div> <p style="text-align: justify;">What about if we went in the other direction? As far as we know, there is no limit to how big an object can be <d-footnote>That is, as long as it doesn't collapse under its weight by the Tolman-Oppenheimer-Volkoff limit. Which again, is a separate topic of discussion.</d-footnote><d-cite key="carroll2017big"></d-cite> That being said, you might have heard of statements regarding measuring the size of the universe. It is how we can make the previous statement that there are around \(10^{80}\) atoms in the known universe. <d-cite key="davies1978tailor"></d-cite> However, this contrasts with observations of the cosmic microwave background radiation and large-scale structures that appear to be distributed uniformly on scales up to hundreds of millions of light-years. These all point to the fact that as far as we can tell, the universe’s expansiveness is infinite. How are these ideas able to reconcile with each other? We can measure the observable universe, which is estimated to be about 93 billion light-years in diameter, but the universe is considered infinite in terms of its extent. Light takes time to travel these massive distances, and by the time they reach an observer, they’ve already become outdated measurements. In addition, results agree that the universe’s expansion is accelerating, without any sign that it could stop. So even if the size of the universe was not infinity, it appears to be heading in that direction. <d-cite key="frieman2008dark"></d-cite></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/Journal/assets/img/Infinity/MeasuringUniverse-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/Journal/assets/img/Infinity/MeasuringUniverse-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/Journal/assets/img/Infinity/MeasuringUniverse-1400.webp"/> <img src="/Journal/assets/img/Infinity/MeasuringUniverse.png" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p style="text-align: justify;">Even though they lead to paradoxical statements, both are considered to be true under relativity. It might seem counter-intuitive, but this is stemming from a challenge in scientific understanding. Multiple theories regarding the same phenomena can be correct under their own set of circumstances. <d-cite key="ludwig2021scientific"></d-cite> Even though it might seem infuriating as a student, this allows a flexible research approach. This leads to novel research, which was the cause, conclusion, and remnants of the foundational crisis of mathematics.</p> <hr/> <h2 id="yeah-we-are-not-quite-there-yet">Yeah, we are not quite there yet</h2> <p style="text-align: justify;">The paradox of infinity has challenged and inspired human understanding for thousands of years, from the ancient Greeks to modern scientists. It raises significant questions about the nature of space and time and challenges our understanding of the physical world. The pursuit of knowledge and understanding in mathematics and science has led to substantial developments and advancements. The existence of multiple theories and explanations for a phenomenon is not a weakness, but rather a strength that allows for continued exploration and discovery. As we continue to explore the mysteries of nature, the pursuit of knowledge in mathematics and physics will continue to be intertwined. This is because each field informs and inspires the other. As we think about the paradox of infinity, we are reminded of the beauty and complexity of the universe. We are also reminded of how endless the possibilities of discovery and exploration are. It illustrates the complex and contradictory nature of academia, where differing theories and ideas can contradict and work against each other. While this can be frustrating and challenging, it ultimately leads to a more dynamic and innovative environment for scientific inquiry. The pursuit of knowledge and understanding requires the willingness to challenge established beliefs and explore novel ideas, and this often involves engaging in rigorous debate and criticism. While we may never fully understand the true nature of infinity, the pursuit of knowledge and understanding continues to inspire us to push the limits of our understanding. This leads to discoveries and breakthroughs that benefit all of humanity.</p> <blockquote> <p>“<em>Science is not only compatible with spirituality; it is a profound source of spirituality. When we recognize our place in an immensity of light years and in the passage of ages, when we grasp the intricacy, beauty, and subtlety of life, then that soaring feeling, that sense of elation and humility combined, is surely spiritual.</em>” - Carl Sagan</p> </blockquote> <d-cite key="sagan2011demon"></d-cite>]]></content><author><name>Roberto A. Gambarini</name></author><category term="Mathematics"/><category term="Physics"/><summary type="html"><![CDATA[So... are we there yet?]]></summary></entry></feed>